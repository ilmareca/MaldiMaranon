
# MaldiMaranon

This project contains scripts to clean and organize bacteria data from XML and ZIP files. The scripts process data, extract relevant information, and generate reports in various formats.

## Files

### `aggregate_species_data.py`
This script aggregates species data from multiple sources and generates a consolidated report to ensure consistency and accuracy across datasets.

**Main Functions**:
- `aggregate_data()`: Aggregates data from various sources.
- `generate_report()`: Generates a consolidated report in CSV format.

**Usage**:
To run the script, use the following command:
```sh
python aggregate_species_data.py
```

### `bacteria_data_cleaner.py`
The main script of the project. It processes XML files within ZIP archives, extracts relevant data, and organizes files into a structured directory. It also generates reports in CSV, JSON, and XML formats.

**Main Functions**:
- `setup_logging(year)`: Sets up logging with file names that include the specified year.
- `process_analyte(analyte, analyte_validation_log)`: Processes an analyte element to extract genus, species, extern_id, and target_position.
- `zip_and_move_folder(zip_ref, folder_name, new_dest_path, directory_move_log, error_log)`: Extracts and moves a folder from a ZIP file to a new destination.
- `organize_files(valid_entries, analyte_zip_found_log, directory_move_log, error_log, zip_file_path, base_dest_dir)`: Organizes files by extracting and moving folders based on valid entries.
- `find_xml_files(xml_found_log, analyte_validation_log, error_log, xml_file_path, year, test_mode=False)`: Finds and processes XML files in a ZIP file within a specific year folder.
- `generate_reports(df, base_dest_dir, year)`: Generates CSV, JSON, and XML reports from a DataFrame.
- `main()`: The main function to run the data cleaner.

**Usage**:
To run the script, use:
```sh
python bacteria_data_cleaner.py
```
You will be prompted to specify whether you are running a test and to enter the year you want to process (e.g., 2020).

### `bacteria_data_cleaner_19.py` and `bacteria_data_cleaner_23.py`
These scripts are customized versions of `bacteria_data_cleaner.py`, specifically adjusted for data from 2019 and 2023. The core functionality remains the same, with adjustments for unique data formats or structures encountered in those years.

**Usage**:
To run the script for 2019:
```sh
python bacteria_data_cleaner_19.py
```
To run the script for 2023:
```sh
python bacteria_data_cleaner_23.py
```

### `count_samples.py`
This script counts the number of samples in the dataset, helping determine the dataset's scale and generating a summary report.

**Main Functions**:
- `count_samples(base_dir)`: Traverses the directory structure and counts the samples.
- `generate_report(data)`: Generates a report in CSV, JSON, and XML formats.

**Usage**:
To run the script, use:
```sh
python count_samples.py
```

## `data_cleaner_results/`
This directory contains the results generated by `bacteria_data_cleaner.py`. Subdirectories for each processed year contain:

- `log_files/`: Stores log files generated during processing.
  - `xml_found_log_{year}.txt`
  - `analyte_validation_log_{year}.txt`
  - `analyte_zip_found_log_{year}.txt`
  - `directory_move_log_{year}.txt`
  - `error_log_{year}.txt`
- `matched_bacteria/`: Contains bacteria folders organized by genus and species.
- `stats/`: Contains reports in CSV, JSON, and XML formats.

## Usage Summary
To run the main script, use the following command:
```sh
python bacteria_data_cleaner.py
```
